## 1. 요구사항 분석

본 프로젝트(Narratix)의 핵심 기능 중 하나는 "사용자가 업로드한 자기소개서 PDF에서 텍스트를 추출하고, 이를 AI를 이용해 질문, 답변 문항 단위로 파싱하고 문항유형을 분석한 결과를 제공하는 것"입니다.

이를 위해 다음과 같은 요구사항을 만족해야 했습니다.

1.  라벨링 시작 버튼을 누르면 사용자는 화면을 벗어날 수 있고, 내부적으로 모든 과정 거쳐, 모든 과정 완료 시 라벨링 완료를 sse알림을 주는 기능입니다.
2. **대용량 파일 처리:** PDF 파일이 다수 업로드되더라도 메인 서버(EC2)의 대역폭이나 메모리가 고갈되지 않아야 한다.
3. **무거운 연산의 분리:** PDF 텍스트 추출 및 AI 분석은 CPU 집약적이고 시간이 오래 걸리는 작업이므로, 메인 웹 서버의 스레드를 블로킹(Blocking)해선 안 된다.
4. **안정적인 에러 핸들링 및 상태 동기화:** 각 단계에서 작업이 실패할 경우, 실패처리가 명확히 되어야하며 DB에 정확히 반영되어 상태가 알맞게 기록되어야한다.
5. 한 업로드에 대한 파일들 처리가 모두 끝났을 때 성공,실패 한 파일 개수를 포함한 알림을 보내야하며 알림이 절대 누락되서는 안된다. 사용자가 업로드완료 결과 화면으로 돌아올 수 있는 유일한 방법이기에 반드시 알림이 바르게 가야한다.

---

## 2. 왜 동기가 아닌 비동기가 필요한가?

이 프로젝트의 파이프라인(PDF 업로드 → 텍스트 추출 → AI 분석 → DB 저장)을 단일 API에서 동기식(Synchronous)으로 처리하지 않고, 큐(SQS)와 이벤트 기반 비동기 구조로 분리한 이유는 다음 3가지 치명적인 문제를 방지하기 위해서입니다.

1. **Tomcat 스레드 풀 고갈 방지 (서버 가용성 확보):** PDF에서 텍스트를 추출하고 외부 Gemini AI API를 호출하여 분석하는 작업은 수십 초 이상이 소요되는 무거운작업입니다. 동기식으로 처리하면 요청이 끝날 때까지 서버의 스레드가 블로킹 됩니다. 다수의 사용자가 동시에 업로드할 경우 스레드 풀이 순식간에 고갈되어 메인 웹 서버(EC2) 전체가 다운되는 장애로 이어집니다.
2. **사용자 경험(UX) 극대화:** 사용자가 "라벨링 시작" 버튼을 누른 후 수십 초 동안 로딩 화면만 보고 있어야 한다면 이탈률이 급증할 것입니다. 비동기 처리를 통해 서버는 즉시 `200 OK`를 응답하고, 사용자는 다른 페이지로 자유롭게 이동할 수 있게 됩니다.
3. **부분 실패 복구 및 장애 격리(Fault Tolerance):** 긴 과정 중 AI API 연동이나 DB 저장에서 일시적인 에러가 발생했을 때, 동기식이라면 처음부터 다시 업로드해야 합니다. SQS를 활용한 비동기 큐 구조를 도입하면, 실패한 지점부터 재시도하거나 처리 불가한 메시지를 DLQ(Dead Letter Queue)로 격리하여 시스템의 안정성을 획기적으로 높일 수 있습니다.

---

## 3. 핵심 컴포넌트 선정 및 조합

이러한 요구사항을 해결하기 위해 단일 스프링 부트 서버에 모든 로직을 넣는 대신, AWS의 관리형 서비스와 AI API를 조합하여 결합도는 낮추고 처리 효율은 높인 분산 아키텍처를 설계했습니다.

- **Spring Boot (EC2):** 메인 비즈니스 로직 통제 및 상태 관리. 다중 파일 단위의 `Job` 트랜잭션을 관리하며, 클라이언트에게 실시간 알림(SSE) 제공.
- **AWS S3 + Presigned URL:** 파일 저장소. 메인 서버의 대역폭 고갈을 막기 위해 클라이언트가 직접 파일을 업로드(Direct Upload)하도록 구성.
- **AWS Lambda (Python):** 무거운 CPU 연산 격리. 메인 서버와 분리된 독립적인 환경에서 PyPDF2를 이용해 문서의 텍스트 추출 수행.
- **AWS SQS:** 비동기 메시지 큐. 람다의 작업 결과를 스프링 워커(Worker) 스레드로 안전하게 전달하며, 트래픽 스파이크 시 서버 부하를 조절하는 버퍼(Buffer) 역할.
- **Gemini AI (LLM API):** 핵심 데이터 가공 및 분석. SQS를 통해 수신한 PDF 텍스트와 최적화된 프롬프트를 조합하여 API를 호출하고, 자기소개서의 '제목, 답변, 문항 유형'을 구조화된 데이터로 라벨링.

---

## 4. 아키텍처 설계 과정 및 주요 의사결정

아키텍처를 하나씩 조립해 나가는 과정에서 직면한 문제들과 해결책입니다.


파일단위로 람다로 가지만 한 번의 업로드 단위로 완료 여부를 따져야 하기에 업로드와 -파일을 연결해줘야했고 , job이라는 엔티티를 만들어 하나의 잡에 파일을 먀칭시켰습니다 job이 업로드 단위.

처음에는 “업로드 시작“ 버튼을 사용자가 누르면, presigned url 발급부터 업로드, 이후 모든 로직이 일어나도록 설계했습니다

이때 업로드 실패 시, 어떻게 처리할지가 복잡했습니다.

잡 생성 시기도 문제였습니다. 프리사인드 유알엘 발급 시에 잡을 생성하면

하나의 업로드 

### 🎯 1: 다중 파일 상태 관리를 위한 `Job` 엔티티 도입과 생성 시점

- **문제:** 사용자는 한 번에 여러 개의 파일을 업로드합니다. 각 파일은 개별적으로 람다와 SQS를 거치는데, **"이 파일들이 모두 끝났는지"** 어떻게 알고 사용자에게 '최종 완료 알림'을 보낼 것인가가 문제였습니다.
- **해결:** 한 번의 업로드 요청 단위를 묶는 `Job` 엔티티를 설계했습니다. (1 Job = N Files)
- **Job 생성 시점 최적화 고민:** 처음에 'Presigned URL 발급 시점'에 Job을 생성하려 했으나, 사용자가 URL만 받고 업로드를 취소하면 DB에 **좀비 데이터**가 남는 문제가 있었습니다. 따라서 사용자가 S3 업로드를 완료하고 **'라벨링 시작' 버튼을 누를 때 백엔드로 요청을 보내 Job을 생성**하도록 설계하여 데이터 정합성을 맞추었습니다.

### 🎯 2: 파일 업로드 방식 - `Multipart` vs `Presigned URL`

- **문제:** 클라이언트가 백엔드(Spring)로 파일을 보내고, 백엔드가 다시 S3로 업로드하면 트래픽이 2배로 발생하고 메인 서버의 병목이 발생합니다.
- **해결:** **S3 Presigned URL** 패턴 도입. 백엔드는 'S3에 업로드할 수 있는 임시 티켓(URL)'만 발급하고 빠집니다. 클라이언트는 이 URL을 사용해 S3로 파일을 직행(Direct Upload)시킵니다.

### 🎯 3: 람다 트리거의 주도권 (S3 Event vs Spring Direct Invocation)

- **초기 설계:** 파일이 S3에 올라가면 S3가 알아서 람다를 깨우는 방식(S3 Event Trigger)을 고려했습니다.
- **문제:** S3 업로드 완료 시 S3가 알아서 람다를 트리거하는 방식(S3 Event)은 간편하지만, 메인 백엔드가 람다의 시작 여부나 실패를 통제할 수 없어 Job 상태 관리가 어려웠습니다.
- **해결:** 백엔드 중심의 상태 관리를 위해, 프론트엔드가 "업로드 완료" API를 호출하면 **Spring 서버가 AWS SDK를 통해 람다를 직접 호출(Direct Invocation)**하도록 주도권을 가져왔습니다.



### 🎯 4: 람다 호출 방식의 딜레마 (동기 블로킹 vs 비동기 EVENT)

- **문제 :** 람다를 동기로 부르면 타임아웃이 나고, 스프링 내부 비동기(`@Async`)로 부르자니 람다 호출 자체가 실패(인프라/권한 에러)했을 때 메인 트랜잭션 롤백이 안 되어 DB 정합성이 깨졌습니다.
- **해결 (Fail-Fast와 비동기의 결합):** 스프링 메인 스레드에서 람다를 동기적으로 호출하되, 호출 타입을 `InvocationType.EVENT` (비동기 호출 모드)로 설정했습니다.
    - 이렇게 하면 AWS가 0.05초 만에 `202 Accepted`를 반환하므로 **서버 지연 없이 즉시 클라이언트에게 응답**할 수 있습니다.
    - 동시에, 권한 부족 등 초기 인프라 에러가 발생하면 즉각 예외를 던져 롤백하고 클라이언트에게 500 에러를 반환하는 **Fail-Fast**를 완벽하게 보장했습니다.

### 🎯 5: 결과 수집 및 실시간 알림 (AWS SQS & SSE)

- **해결:** 람다 내부에서 PDF 텍스트 추출이 비동기적으로 완료되면, 그 결과가 **AWS SQS**에 적재됩니다. Spring 서버는 롱 폴링(Long Polling)으로 결과를 가져와 Gemini AI를 통해 문항 유형을 분석하고 DB 상태를 업데이트합니다.
- **알림 보장:** 각 파일의 처리가 끝날 때마다 Job의 전체 파일 완료 여부를 검사합니다. 모든 처리가 완료되면(성공/실패 포함) SSE를 통해 다른 페이지에 가 있는 사용자에게 누락 없이 라벨링 완료 알림을 푸시합니다.



---

## 5. 최종 전체 시스템 흐름도 (Sequence Flow)

1. 클라이언트가 파일 업로드를 위해 백엔드에 S3 Presigned URL을 요청합니다.
2. **[직접 업로드]** 클라이언트가 Presigned URL을 발급받아 AWS S3에 다수의 PDF를 업로드합니다.
3. **[작업 생성]** 업로드 완료 후 프론트가 POST `/api/jobs`를 호출하면, 서버는 DB에 `Job`과 여러 `File` 상태를 `PENDING`으로 저장합니다.
4. **[안전한 람다 호출]** 서버가 AWS SDK로 람다를 호출(`EVENT` 타입)합니다. (초기 인프라 에러 시 즉시 롤백)
5. **[빠른 응답]** 람다 호출 접수(202) 즉시 클라이언트에게 200 OK를 반환하여 사용자가 화면을 벗어날 수 있게 합니다.
6. **[추출 및 대기열 적재]** 람다가 무거운 PDF 텍스트 추출 로직을 수행하고, 완료/실패 여부를 SQS로 전송합니다.
7. **[AI 분석 및 상태 동기화]** Spring 서버가 SQS에서 메시지를 소비하여 Gemini AI 라벨링 연산을 수행하고 개별 파일 상태를 업데이트합니다.
8. **[최종 알림 발송]** Job에 속한 모든 파일의 처리가 끝나면, SSE를 통해 클라이언트에게 최종 완료 알림(성공/실패 건수 포함)을 실시간으로 전송합니다.